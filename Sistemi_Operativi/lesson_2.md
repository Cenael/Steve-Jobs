# ğŸš€ Processi, Thread e Scheduling: Come il Sistema Operativo Organizza il Lavoro

## ğŸ’» 1. Concetto di Processo

Un **processo** Ã¨ l'unitÃ  fondamentale di esecuzione in un sistema operativo. Non Ã¨ solo un programma, ma un'entitÃ  attiva che comprende il programma in esecuzione, i suoi dati e tutte le risorse necessarie. 

### ğŸ§© Caratteristiche principali:
- **Immagine in memoria** ğŸ§ : codice, dati, stack e heap
- **Program Counter (PC)** ğŸ”: punta alla prossima istruzione
- **Registri CPU** âš™ï¸: contengono dati temporanei
- **Risorse allocate** ğŸ“Š: memoria, file, dispositivi I/O

Durante il suo ciclo di vita, un processo attraversa diversi stati: **new** (appena creato), **ready** (pronto per l'esecuzione), **running** (in esecuzione), **blocked** (in attesa di un evento) e **terminated** (completato).

Il sistema operativo tiene traccia dei processi tramite il **Process Control Block (PCB)** ğŸ“, una struttura dati che contiene tutte le informazioni necessarie per gestire il processo: PID, stato, valori dei registri e altro ancora. Grazie al PCB, il sistema puÃ² sospendere un processo e riprenderlo esattamente dal punto in cui era stato interrotto.

## ğŸ”„ 2. Manipolazione dei Processi

La gestione dei processi Ã¨ fondamentale per il funzionamento di un sistema operativo moderno.

### ğŸŒ± Creazione dei processi
Nei sistemi Unix-like, i processi vengono creati principalmente attraverso due operazioni: 
- **fork()** ğŸ´: crea un nuovo processo (figlio) come copia del chiamante
- **exec()** ğŸš€: carica un nuovo programma nel processo

Queste operazioni permettono di costruire una struttura gerarchica ad albero, dove ogni processo (tranne il processo iniziale) ha un padre.

### â¹ï¸ Terminazione dei processi
Un processo puÃ² terminare in vari modi: normalmente al completamento, a causa di un errore o forzatamente da un altro processo. In ogni caso, il sistema operativo si occupa di rilasciare tutte le risorse allocate.

### ğŸ’¬ Comunicazione tra processi
I processi separati possono comunicare e coordinarsi attraverso vari meccanismi:

- **Memoria condivisa** ğŸ¤: accesso alla stessa area di memoria
- **Scambio di messaggi** ğŸ“¨: invio di pacchetti di informazioni
- **Pipe e socket** ğŸ“¡: canali di comunicazione tra processi
- **Semafori** ğŸš¦: meccanismi di sincronizzazione

La sincronizzazione Ã¨ cruciale quando piÃ¹ processi condividono risorse. Senza di essa, possono verificarsi **race condition** ğŸ, situazioni in cui il risultato dipende dall'ordine imprevedibile di esecuzione dei processi.

## ğŸ§µ 3. Processi Leggeri (Threads)

I **thread** rappresentano un'evoluzione del concetto di processo, offrendo un modello piÃ¹ leggero e flessibile. Immagina i thread come "mini-processi" all'interno di un processo.

### ğŸ”„ Thread vs Processi
Mentre i processi hanno spazi di memoria completamente separati, i thread di uno stesso processo condividono:
- Lo stesso spazio di indirizzamento ğŸ 
- I file aperti ğŸ“‚
- Altre risorse del processo ğŸ”§

Questo rende la creazione e la commutazione tra thread molto piÃ¹ veloce rispetto ai processi, ma introduce nuove sfide legate alla sincronizzazione.

### ğŸ§ª Tipi di thread
- **Thread a livello utente (ULT)** ğŸ‘¤: gestiti da librerie nel livello applicativo
- **Thread a livello kernel (KLT)** âš™ï¸: gestiti direttamente dal sistema operativo
- **Modello ibrido** ğŸ”„: combina entrambi gli approcci

### âœ¨ Vantaggi dei thread
L'uso dei thread offre numerosi benefici: condivisione efficiente delle risorse, maggiore reattivitÃ  delle applicazioni, migliore sfruttamento dei sistemi multiprocessore e comunicazione semplificata. Tuttavia, la programmazione multithreading introduce anche sfide legate alla sincronizzazione e al rischio di **deadlock** ğŸ”’, situazioni di stallo in cui due o piÃ¹ thread si bloccano a vicenda.

## â±ï¸ 4. Scheduling dei Processori

Lo **scheduling** Ã¨ il meccanismo con cui il sistema operativo decide quale processo o thread deve essere eseguito in un determinato momento.

### ğŸ¯ Obiettivi dello scheduling
Un buon algoritmo di scheduling deve bilanciare diversi obiettivi:
- Massimizzare l'utilizzo della CPU ğŸ’ª
- Minimizzare il tempo di attesa â°
- Garantire equitÃ  tra i processi âš–ï¸
- Massimizzare il throughput ğŸ“ˆ
- Minimizzare il tempo di risposta âš¡

### ğŸ•°ï¸ Livelli di scheduling
- **A breve termine** â±ï¸: decide quale processo mandare in esecuzione
- **A medio termine** ğŸ“†: gestisce lo swapping tra memoria e disco
- **A lungo termine** ğŸ“…: decide quali processi ammettere nel sistema

### ğŸ§® Principali algoritmi di scheduling

#### 1. First-Come, First-Served (FCFS) ğŸ
Il primo processo che arriva Ã¨ il primo ad essere servito. Semplice ma puÃ² penalizzare processi brevi che arrivano dopo processi lunghi.

#### 2. Shortest Job First (SJF) ğŸƒâ€â™‚ï¸
Esegue prima i processi con tempo di esecuzione piÃ¹ breve. Ottimo per minimizzare il tempo medio di attesa, ma richiede di conoscere o stimare la durata dei processi.

#### 3. Priority Scheduling ğŸ†
Assegna prioritÃ  ai processi e serve prima quelli a prioritÃ  piÃ¹ alta. Rischio: i processi a bassa prioritÃ  potrebbero non essere mai eseguiti (starvation).

#### 4. Round Robin (RR) ğŸ”„
Assegna a ciascun processo un quanto di tempo fisso, al termine del quale il processo viene rimesso in coda. Garantisce una buona responsivitÃ , ideale per sistemi interattivi.

### ğŸ“Š Valutazione degli algoritmi
Per misurare l'efficacia di un algoritmo di scheduling, si considerano:
- Tempo di attesa â³
- Tempo di risposta âš¡
- Tempo di completamento ğŸ
- Throughput ğŸ“ˆ
- Utilizzo della CPU ğŸ’»

Lo scheduling Ã¨ un compromesso tra efficienza e equitÃ , tra la massimizzazione delle prestazioni del sistema e la soddisfazione delle esigenze degli utenti. Un buon algoritmo di scheduling adatta la sua strategia al contesto specifico, che si tratti di un server, un desktop o un dispositivo embedded.